{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epinions</th>\n",
       "      <th>Slashdot</th>\n",
       "      <th>Wikipedia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nodes</th>\n",
       "      <td>131828</td>\n",
       "      <td>82140</td>\n",
       "      <td>7118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edges</th>\n",
       "      <td>841372</td>\n",
       "      <td>549202</td>\n",
       "      <td>103747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+edge</th>\n",
       "      <td>85.300</td>\n",
       "      <td>77.400</td>\n",
       "      <td>78.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-edge</th>\n",
       "      <td>14.700</td>\n",
       "      <td>22.600</td>\n",
       "      <td>21.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triads</th>\n",
       "      <td>13317672</td>\n",
       "      <td>1508105</td>\n",
       "      <td>790532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Epinions Slashdot Wikipedia\n",
       "Nodes     131828    82140      7118\n",
       "Edges     841372   549202    103747\n",
       "+edge     85.300   77.400    78.800\n",
       "-edge     14.700   22.600    21.200\n",
       "Triads  13317672  1508105    790532"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load necessary libraries and the datasets\n",
    "%load_ext autoreload\n",
    "import pandas as pd\n",
    "#using networkx for triads\n",
    "import networkx as nx\n",
    "PATH = \"data/\"\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import csv\n",
    "import pickle \n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "#Reloading the parsed datasets + triad dicts + table1 in case\n",
    "#Epinions\n",
    "epinions = pd.read_csv(PATH+\"soc-sign-epinions.txt\", sep=\"\\t\", \n",
    "                       header=None, names = [\"FromNodeId\", \"ToNodeId\", \"Sign\"], skiprows = 4)\n",
    "epinions.drop(index=epinions.query('FromNodeId == ToNodeId').index, inplace=True)\n",
    "epinions.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#Slashdot\n",
    "slashdot = pd.read_csv(PATH+\"soc-sign-Slashdot090221.txt\",sep= \"\\t\", \n",
    "                       header=None, names = [\"FromNodeId\", \"ToNodeId\", \"Sign\"], skiprows = 4)\n",
    "slashdot.drop(index=slashdot.query('FromNodeId == ToNodeId').index, inplace=True)\n",
    "slashdot.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#Wiki\n",
    "wiki = pd.read_csv(PATH+\"parsed_wiki.csv\", header=0)\n",
    "wiki.drop(index=wiki.query('FromNodeId == ToNodeId').index, inplace=True)\n",
    "wiki.reset_index(inplace=True,drop=True)\n",
    "\n",
    "#Table 1\n",
    "with open('./data/table1.pkl', 'rb') as f:\n",
    "    table1 = pd.read_pickle(f)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "table1.loc[[\"Nodes\",\"Edges\",\"Triads\"]] = table1.loc[[\"Nodes\",\"Edges\",\"Triads\"]].astype(int)\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the replication is largely built NetworkX. The proposed functions didn't work, so I figured I'd go into the source code and adapt it to my use. Basically, I wanted to get the types of triad for a given set of 3 nodes, then decide how to count them.\n",
    "\n",
    "Also, I have taken a piece of code from this [link](https://www.cl.cam.ac.uk/teaching/1314/L109/tutorial.pdf), just the loop from page 41, to loop on all nodes efficiently because initially, I used a directed view of the graph only to generate all triads and loop (see hidden Raw cell below if you want to check that), but after having the method run for over 4 hours on Wikipedia alone, I gave up and looked for another way.\n",
    "\n",
    "In my final version of `get_triad_types`, I used an undirected view of the graph to get neighbors more easily (see docstring), then used a directed view of the graph to get all the triad infos I needed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# See cell above for \n",
    "# Now : Iterate over generator of all triads.\n",
    "# Get the triads that appear in names of interest\n",
    "# For those triad, get subgraph, edges\n",
    "\n",
    "# Do the loop checking.\n",
    "# Get the triangles --> Count the triangle types\n",
    "#Requires numpy for numpy.unique\n",
    "import tqdm\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "def count_triad_types_old(G):\n",
    "    \n",
    "    result = pd.DataFrame(np.zeros((4,2),dtype=np.int64),\n",
    "                          index=['T3+++','T1+--','T2++-','T0---'],\n",
    "                          columns = ['count','percentage'])\n",
    "    \n",
    "    gen = nx.all_triads(G)\n",
    "    print(\"ITERATING\")\n",
    "    for triad in gen:\n",
    "        #Getting nodes in a triad\n",
    "        nodeslist = list(triad.nodes())\n",
    "        n0, n1, n2 = nodeslist[0], nodeslist[1], nodeslist[2] \n",
    "        #Getting its name and verifying it's a triad of interest\n",
    "        name = TRICODE_TO_NAME[_tricode(G, n0, n1, n2)]\n",
    "        #Early continue if not of interest\n",
    "        if name not in (names_interest_single+names_interest_multiple):\n",
    "            continue\n",
    "            \n",
    "        edgeview = triad.edges()\n",
    "        if name in names_interest_single:\n",
    "            sign_sum = np.array([(edge, edgeview[edge]['Sign']) for edge in edgeview],\n",
    "                                dtype=object).sum(axis=0)[1]\n",
    "            result.loc[sum_to_type(sign_sum)]['count'] += 1\n",
    "            \n",
    "        elif name in names_interest_multiple:\n",
    "\n",
    "            #Get the set of edges and their sign for this given triplet of interest\n",
    "            list_edges = [(edge, edgeview[edge]['Sign']) for edge in edgeview]\n",
    "\n",
    "            #Form all the triangles possible (combinations of 3 edges)\n",
    "            triangles = list(combinations(list_edges,3))\n",
    "            \n",
    "            #Get mask to get all valid triangles, all true by default\n",
    "            valid_loops_index = np.ones(len(triangles), dtype = bool)\n",
    "            \n",
    "            for idx, tri in enumerate(triangles):\n",
    "                loop = tuple((tri[0][0], tri[1][0], tri[2][0]))\n",
    "                # Counting each time a node appears in a given loop.\n",
    "                # Valid loop must have each node appear 2 times.\n",
    "                _, count = np.unique(loop, return_counts=True)\n",
    "                if (1 in count) or (3 in count):\n",
    "                    #Set invalid to false\n",
    "                    valid_loops_index[idx] = False\n",
    "            #Using fancy indexing, taking the sum of axis = 1 so we get the sum of sign with [:,1] slicing\n",
    "\n",
    "            signs_sum = np.array(triangles,dtype=object)[valid_loops_index].sum(axis=1)[:,1]\n",
    "            \n",
    "            for number in np.unique(signs_sum):\n",
    "                result.loc[sum_to_type(number)]['count'] += len(signs_sum[signs_sum==number])\n",
    "                \n",
    "    result['percentage'] = result['count']/ result['count'].sum()\n",
    "    print(\"DONE :: Returning dataframe containing results\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For a given triplet of connected nodes, I get the tricode (from NetworkX sourcecode) and get its name to see whether it was a triad of interest.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMENTS FOR THE ASSISTANTS HERE (the rest is just my textual description for the final submission)\n",
    "\n",
    "So. This is what I do, in bulletpoints.\n",
    "\n",
    "- Algorithm : \n",
    "    - Instead of triadic census, I use a for iteration on nodes and its neighbours to get the triangles. \n",
    "    - Using sourcecode from NetworkX, I get the triangle types and only keep the ones of interest \n",
    "    - Then, from those triangles, I get the edges and form combinations of 3 edges.\n",
    "    - Then I find the closed loops to keep valid triangles. \n",
    "    - **From those closed triangles, I get the edge signs, and simply add them (see `sum_to_type` below)** (this is the part where I classify a triangle to its type, T1, T2, etc.)\n",
    "    - Then I simply add the count +=1 (since the count is correct and the classification is not, I don't know)\n",
    "- After this, I shuffle the edge signs randomly using `pd.df.sample(frac=1)` (see `shuffle_sign` below) and repeat my algorithm and save all the results in table3 (see `get_results_table3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================My own method below=====================\n",
    "def sum_to_type(number):\n",
    "    \"\"\"\n",
    "    Converts the sum of signs (+/- 1) in a given triangle to its type of triads \n",
    "    returns a string.\n",
    "    \"\"\"\n",
    "    type_name = ''\n",
    "    if number == 3:\n",
    "        type_name = 'T3+++'\n",
    "        \n",
    "    if number == 1:\n",
    "        type_name = 'T2++-'\n",
    "        \n",
    "    if number == -1:\n",
    "        type_name = 'T1+--'\n",
    "        \n",
    "    if number == -3:\n",
    "        type_name = 'T0---'\n",
    "    return type_name\n",
    "#==========================================================\n",
    "\n",
    "#utilities&methods that are within the NetworkX package source code, on which I will build my method for triad \n",
    "def _tricode(G, v, u, w):\n",
    "    \"\"\"Returns the integer code of the given triad.\n",
    "\n",
    "    This is some fancy magic that comes from Batagelj and Mrvar's paper. It\n",
    "    treats each edge joining a pair of `v`, `u`, and `w` as a bit in\n",
    "    the binary representation of an integer.\n",
    "\n",
    "    \"\"\"\n",
    "    combos = ((v, u, 1), (u, v, 2), (v, w, 4), (w, v, 8), (u, w, 16), (w, u, 32))\n",
    "    return sum(x for u, v, x in combos if v in G[u])\n",
    "\n",
    "#: The integer codes representing each type of triad.\n",
    "#: Triads that are the same up to symmetry have the same code.\n",
    "TRICODES = (1, 2, 2, 3, 2, 4, 6, 8, 2, 6, 5, 7, 3, 8, 7, 11, 2, 6, 4, 8, 5, 9,\n",
    "            9, 13, 6, 10, 9, 14, 7, 14, 12, 15, 2, 5, 6, 7, 6, 9, 10, 14, 4, 9,\n",
    "            9, 12, 8, 13, 14, 15, 3, 7, 8, 11, 7, 12, 14, 15, 8, 14, 13, 15,\n",
    "            11, 15, 15, 16)\n",
    "\n",
    "#: The names of each type of triad. The order of the elements is\n",
    "#: important: it corresponds to the tricodes given in :data:`TRICODES`.\n",
    "TRIAD_NAMES = ('003', '012', '102', '021D', '021U', '021C', '111D', '111U',\n",
    "               '030T', '030C', '201', '120D', '120U', '120C', '210', '300')\n",
    "\n",
    "#: A dictionary mapping triad code to triad name.\n",
    "TRICODE_TO_NAME = {i: TRIAD_NAMES[code - 1] for i, code in enumerate(TRICODES)}\n",
    "\n",
    "#Triad names of interest (see replication_report1)\n",
    "names_interest_single = [\"030T\",\"030C\"]\n",
    "names_interest_multiple = [\"120D\",\"120U\",\"120C\",\"210\", \"300\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the three nodes form a triplet of interest, I check which type it is. \n",
    "Then I generate, for all the edges associated with the subgraph of those three nodes, a combination of 3 edges, to form all possible triplets.\n",
    "\n",
    "From those, I must filter those that do not form a closed loop, i.e. I only keep the triplets where every node is accessible from any node.\n",
    "Then, I keep those triangles, get the sign attributes sum, and get which type each triangle is (T3, T2, T1, T0) using `sum_to_type()` defined above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_triad_types(pandas_edgelist):\n",
    "    \"\"\"\n",
    "    Built upon some items from the source code of networkX such as _tricode, \n",
    "    tricode_to_name dict etc as well a loop of code I've found from \n",
    "    https://www.cl.cam.ac.uk/teaching/1314/L109/tutorial.pdf\n",
    "    which provides an iteration which is infinitely faster than the whatever is coded by NetworkX's creators\n",
    "    \n",
    "    Input : pandas_edgelist to create Directed AND undirected version of the same graph\n",
    "    Output : a pandas.DF of the count of each type of triads\n",
    "    \n",
    "    for a given NetworkX directed Graph G\n",
    "    A triangle is formed from 3 connected nodes.\n",
    "    A triangle is a valid one if it forms a loop.\n",
    "    We verify that the 3 nodes form a triad of interest by checking against \n",
    "    Triad name using tricode_to_name\n",
    "    ex : \n",
    "        ((6,3), (6,10), (10,3)) is a valid triangle.\n",
    "        ((6,3), (6,10), (3,6)) is not valid.\n",
    "        \n",
    "    Below, for tri in triangles, tri contains the edges and their sign.\n",
    "    ex: for ((6,3), 1)\n",
    "        tri[x][0] gives the tuple corresponding to the x'th edge in a triangle\n",
    "        tri[x][1] gives the sign of the x'th edge in a triangle\n",
    "    \n",
    "    Then, getting sum of signs of valid triangles(using mask), I count the value\n",
    "    of signs for each triangle (3 = +++, 1 = ++-, -1 = +--, -3 = ---)\n",
    "    \"\"\"\n",
    "    print(\"Creating graphs\")\n",
    "    G_directed = nx.from_pandas_edgelist(pandas_edgelist, \"FromNodeId\",\"ToNodeId\",edge_attr=\"Sign\",create_using=nx.DiGraph)\n",
    "    undirected = nx.from_pandas_edgelist(pandas_edgelist, \"FromNodeId\",\"ToNodeId\",edge_attr=\"Sign\",create_using=nx.Graph)\n",
    "    \n",
    "    result = pd.DataFrame(np.zeros((4,2),dtype=np.int64),\n",
    "                          index=['T3+++','T1+--','T2++-','T0---'],\n",
    "                          columns = ['count','fraction'])\n",
    "    # iteration over all nodes\n",
    "    print(\"Iterating\")\n",
    "    nodes = undirected.nodes()\n",
    "    #Get neighbors. Use undirected view to get to/from nodes at once\n",
    "    #This same code for neighbors using a directed view yielded only nodes to which n0 was connected,\n",
    "    #rather than both TO_nodes and FROM_nodes for n0, n1, etc.\n",
    "    for n0 in nodes:\n",
    "        neighbors1 = set(undirected[n0]) \n",
    "        for n1 in filter(lambda x: x>n0, neighbors1):\n",
    "            neighbors2 = set(undirected[n1])\n",
    "            common = neighbors1 & neighbors2 #common neighbors\n",
    "            \n",
    "            #Filter avoids repetition\n",
    "            for n2 in filter(lambda x: x>n1, common): \n",
    "            \n",
    "                #From this part on, I use directed graph for triad analysis.\n",
    "                name = TRICODE_TO_NAME[_tricode(G_directed, n0, n1, n2)]\n",
    "                \n",
    "                #Early continue if name is not of interest, avoids computing billions of triads\n",
    "                if name not in (names_interest_single+names_interest_multiple):\n",
    "                    continue\n",
    "                    \n",
    "                #Get edges of the subgraph of 3 nodes (triangle), then check which type \n",
    "                #of triad it is and do appropriate calculations\n",
    "                edgeview = G_directed.subgraph((n0,n1,n2)).edges()\n",
    "                \n",
    "                if name in names_interest_single:\n",
    "                    sign_sum = np.array([(edge, edgeview[edge]['Sign']) for edge in edgeview],\n",
    "                                        dtype=object).sum(axis=0)[1]\n",
    "                \n",
    "                    result.loc[sum_to_type(sign_sum)]['count'] += 1\n",
    "                    \n",
    "                elif name in names_interest_multiple:\n",
    "        \n",
    "                    #Get the set of edges and their sign for this given triplet of interest\n",
    "                    list_edges = [(edge, edgeview[edge]['Sign']) for edge in edgeview]\n",
    "        \n",
    "                    #Form all the triangles possible (combinations of 3 edges)\n",
    "                    triangles = list(combinations(list_edges,3))\n",
    "                    \n",
    "                    #Get mask to get all valid triangles, all true by default\n",
    "                    valid_loops_index = np.ones(len(triangles), dtype = bool)\n",
    "                    \n",
    "                    for idx, tri in enumerate(triangles):\n",
    "                        loop = tuple((tri[0][0], tri[1][0], tri[2][0]))\n",
    "                        # Counting each time a node appears in a given loop.\n",
    "                        # Valid loop must have each node appear 2 times.\n",
    "                        _, count = np.unique(loop, return_counts=True)\n",
    "                        if (1 in count) or (3 in count):\n",
    "                            #Set invalid to false\n",
    "                            valid_loops_index[idx] = False\n",
    "                    #Using fancy indexing, taking the sum of axis = 1 so we get the sum of sign with [:,1] slicing\n",
    "        \n",
    "                    signs_sum = np.array(triangles,dtype=object)[valid_loops_index].sum(axis=1)[:,1]\n",
    "                    \n",
    "                    for number in np.unique(signs_sum):\n",
    "                        result.loc[sum_to_type(number)]['count'] += len(signs_sum[signs_sum==number])\n",
    "    \n",
    "    result['fraction'] = result['count']/ result['count'].sum()\n",
    "    print(\"DONE :: Returning dataframe containing results\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get P0, we must shuffle the edge signs, then re-run the functions to get the fractions.\n",
    "def shuffle_sign(df):\n",
    "    \"\"\"\n",
    "    Uses pd.df.sample(frac=1) to shuffle all rows, i.e. shuffle while keeping the distribution.\n",
    "    By dropping before shuffling and re-merging after, we shuffle only the signs.\n",
    "    \"\"\"\n",
    "    df_return = df.copy()\n",
    "    sign_shuffled = df.drop(columns=['FromNodeId','ToNodeId'])\n",
    "    sign_shuffled = sign_shuffled.sample(frac=1)\n",
    "    sign_shuffled.reset_index(inplace=True, drop=True)\n",
    "    df_return['Sign'] = sign_shuffled['Sign']\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graphs\n",
      "Iterating\n",
      "DONE :: Returning dataframe containing results\n",
      "Creating graphs\n",
      "Iterating\n",
      "DONE :: Returning dataframe containing results\n",
      "Creating graphs\n",
      "Iterating\n",
      "DONE :: Returning dataframe containing results\n",
      "Creating graphs\n",
      "Iterating\n",
      "DONE :: Returning dataframe containing results\n",
      "Creating graphs\n",
      "Iterating\n",
      "DONE :: Returning dataframe containing results\n",
      "Creating graphs\n",
      "Iterating\n",
      "DONE :: Returning dataframe containing results\n"
     ]
    }
   ],
   "source": [
    "#Giving count_triad_types the pandas_edgelists (shuffled and unshuffled and printing results)\n",
    "\n",
    "#Shuffling DFs\n",
    "epinions_shuffled = shuffle_sign(epinions)\n",
    "slashdot_shuffled = shuffle_sign(slashdot)\n",
    "wiki_shuffled = shuffle_sign(wiki)\n",
    "\n",
    "#Getting the triad counts for normal and shuffled\n",
    "epi_triads = count_triad_types(epinions)\n",
    "epi_triads_shuffled = count_triad_types(epinions_shuffled)\n",
    "\n",
    "slashdot_triads = count_triad_types(slashdot)\n",
    "slashdot_triads_shuffled = count_triad_types(slashdot_shuffled)\n",
    "\n",
    "wiki_triads = count_triad_types(wiki)\n",
    "wiki_triads_shuffled = count_triad_types(wiki_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_table3(df_normal, df_shuffled):\n",
    "    \"\"\"\n",
    "    Get the results formatted like table3 from the result dataframes returned by count_triad_types\n",
    "    Requires both tables returned using both the normal and shuffled signs dfs\n",
    "    \"\"\"\n",
    "    table3 = pd.DataFrame(np.zeros((4,4),dtype=np.int64),\n",
    "                               index=['T3+++','T1+--','T2++-','T0---'],\n",
    "                               columns = ['count','fraction','prob_p0','surprise'])\n",
    "    table3['count'] = df_normal['count']\n",
    "    table3['fraction'] = df_normal['fraction']\n",
    "    table3['prob_p0'] = df_shuffled['fraction']\n",
    "    \n",
    "    expected = table3['prob_p0']*table3['count'].sum()\n",
    "    denominator = np.sqrt(expected*(1-table3['prob_p0']))\n",
    "    table3['surprise'] = (table3['count']-expected)/denominator\n",
    "    return table3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Table3 to get the results\n",
    "table3_epinions = get_results_table3(epi_triads, epi_triads_shuffled)\n",
    "\n",
    "table3_slashdot = get_results_table3(slashdot_triads, slashdot_triads_shuffled)\n",
    "\n",
    "table3_wiki = get_results_table3(wiki_triads, wiki_triads_shuffled) \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def swap_row(df):\n",
    "    df_return = df.copy()\n",
    "    df_return.loc['T2++-'] = df.loc['T1+--'].copy()\n",
    "    df_return.loc['T1+--'] = df.loc['T2++-'].copy()\n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 3 : \n",
      "\n",
      "#========= Epinions =========#\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_ae73da7b_3329_11eb_b337_a0510b82162f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >count</th>        <th class=\"col_heading level0 col1\" >fraction</th>        <th class=\"col_heading level0 col2\" >prob_p0</th>        <th class=\"col_heading level0 col3\" >surprise</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ae73da7b_3329_11eb_b337_a0510b82162flevel0_row0\" class=\"row_heading level0 row0\" >T3+++</th>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow0_col0\" class=\"data row0 col0\" >11616708</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow0_col1\" class=\"data row0 col1\" >0.872</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow0_col2\" class=\"data row0 col2\" >0.621</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow0_col3\" class=\"data row0 col3\" >1,889.2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ae73da7b_3329_11eb_b337_a0510b82162flevel0_row1\" class=\"row_heading level0 row1\" >T1+--</th>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow1_col0\" class=\"data row1 col0\" >688557</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow1_col1\" class=\"data row1 col1\" >0.052</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow1_col2\" class=\"data row1 col2\" >0.055</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow1_col3\" class=\"data row1 col3\" >-54.2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ae73da7b_3329_11eb_b337_a0510b82162flevel0_row2\" class=\"row_heading level0 row2\" >T2++-</th>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow2_col0\" class=\"data row2 col0\" >924739</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow2_col1\" class=\"data row2 col1\" >0.069</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow2_col2\" class=\"data row2 col2\" >0.321</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow2_col3\" class=\"data row2 col3\" >-1,963.9</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ae73da7b_3329_11eb_b337_a0510b82162flevel0_row3\" class=\"row_heading level0 row3\" >T0---</th>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow3_col0\" class=\"data row3 col0\" >87668</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow3_col1\" class=\"data row3 col1\" >0.007</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow3_col2\" class=\"data row3 col2\" >0.003</td>\n",
       "                        <td id=\"T_ae73da7b_3329_11eb_b337_a0510b82162frow3_col3\" class=\"data row3 col3\" >223.3</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2ade18881c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#========= Slashdot =========#\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_ae74c477_3329_11eb_93e1_a0510b82162f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >count</th>        <th class=\"col_heading level0 col1\" >fraction</th>        <th class=\"col_heading level0 col2\" >prob_p0</th>        <th class=\"col_heading level0 col3\" >surprise</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ae74c477_3329_11eb_93e1_a0510b82162flevel0_row0\" class=\"row_heading level0 row0\" >T3+++</th>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow0_col0\" class=\"data row0 col0\" >1266646</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow0_col1\" class=\"data row0 col1\" >0.840</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow0_col2\" class=\"data row0 col2\" >0.464</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow0_col3\" class=\"data row0 col3\" >924.6</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ae74c477_3329_11eb_93e1_a0510b82162flevel0_row1\" class=\"row_heading level0 row1\" >T1+--</th>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow1_col0\" class=\"data row1 col0\" >115884</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow1_col1\" class=\"data row1 col1\" >0.077</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow1_col2\" class=\"data row1 col2\" >0.119</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow1_col3\" class=\"data row1 col3\" >-158.6</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ae74c477_3329_11eb_93e1_a0510b82162flevel0_row2\" class=\"row_heading level0 row2\" >T2++-</th>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow2_col0\" class=\"data row2 col0\" >109303</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow2_col1\" class=\"data row2 col1\" >0.072</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow2_col2\" class=\"data row2 col2\" >0.406</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow2_col3\" class=\"data row2 col3\" >-833.5</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ae74c477_3329_11eb_93e1_a0510b82162flevel0_row3\" class=\"row_heading level0 row3\" >T0---</th>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow3_col0\" class=\"data row3 col0\" >16272</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow3_col1\" class=\"data row3 col1\" >0.011</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow3_col2\" class=\"data row3 col2\" >0.011</td>\n",
       "                        <td id=\"T_ae74c477_3329_11eb_93e1_a0510b82162frow3_col3\" class=\"data row3 col3\" >-5.6</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2ade690e8b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#========= Wikipedia =========#\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_ae75adea_3329_11eb_9285_a0510b82162f\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >count</th>        <th class=\"col_heading level0 col1\" >fraction</th>        <th class=\"col_heading level0 col2\" >prob_p0</th>        <th class=\"col_heading level0 col3\" >surprise</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ae75adea_3329_11eb_9285_a0510b82162flevel0_row0\" class=\"row_heading level0 row0\" >T3+++</th>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow0_col0\" class=\"data row0 col0\" >555300</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow0_col1\" class=\"data row0 col1\" >0.702</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow0_col2\" class=\"data row0 col2\" >0.494</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow0_col3\" class=\"data row0 col3\" >371.5</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ae75adea_3329_11eb_9285_a0510b82162flevel0_row1\" class=\"row_heading level0 row1\" >T1+--</th>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow1_col0\" class=\"data row1 col0\" >63425</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow1_col1\" class=\"data row1 col1\" >0.080</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow1_col2\" class=\"data row1 col2\" >0.104</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow1_col3\" class=\"data row1 col3\" >-69.7</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ae75adea_3329_11eb_9285_a0510b82162flevel0_row2\" class=\"row_heading level0 row2\" >T2++-</th>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow2_col0\" class=\"data row2 col0\" >163328</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow2_col1\" class=\"data row2 col1\" >0.207</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow2_col2\" class=\"data row2 col2\" >0.393</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow2_col3\" class=\"data row2 col3\" >-339.2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ae75adea_3329_11eb_9285_a0510b82162flevel0_row3\" class=\"row_heading level0 row3\" >T0---</th>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow3_col0\" class=\"data row3 col0\" >8479</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow3_col1\" class=\"data row3 col1\" >0.011</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow3_col2\" class=\"data row3 col2\" >0.009</td>\n",
       "                        <td id=\"T_ae75adea_3329_11eb_9285_a0510b82162frow3_col3\" class=\"data row3 col3\" >12.9</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2ade690ea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying with formatting\n",
    "print(\"Table 3 : \\n\")\n",
    "print(\"#========= Epinions =========#\")\n",
    "display(table3_epinions.style.format({'fraction': \"{:,.3f}\", 'prob_p0': '{:,.3f}', 'surprise' : '{:,.1f}'}))\n",
    "print(\"#========= Slashdot =========#\")\n",
    "display(table3_slashdot.style.format({'fraction': \"{:,.3f}\", 'prob_p0': '{:,.3f}', 'surprise' : '{:,.1f}'}))\n",
    "print(\"#========= Wikipedia =========#\")\n",
    "display(table3_wiki.style.format({'fraction': \"{:,.3f}\", 'prob_p0': '{:,.3f}', 'surprise' : '{:,.1f}'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing with table 3 from the paper, it seems that the values for the first two columns for T2++- and T1+-- have been reversed. Indeed, looking at Wikipedia for example, we see that the count for T1+-- is 63 425 instead of 163328 like in the paper. As a result, the fraction $p(T_{i})$ has also been switched. \n",
    "\n",
    "On the other hand, we notice that the values for $p_{0}(T_{i})$ are the same as in table3. This is quite odd, as the same method was used to compute the type of each triangle generated by the sets of 3 edges. \n",
    "\n",
    "I do not know whether I have made a mistake, or whether the authors of the paper have. If I made a mistake, I do not know where it was from, as I believe my reasoning for the type computation seems sound. I take the sum of the signs, and simply summing $\\pm1$ yields me the four different types of triads. On top of that, I use the exact same method to compute the type of triads for both the normal and the shuffled edge signs, so if I had made a mistake somewhere, the results for both DFs  would have been switched, rather than only one of the two columns.\n",
    "\n",
    "As a result, the values of the last column (surprise) are also different as they rely on the others columns to be computed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
